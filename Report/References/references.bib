@article{KeironsPaper,
 author={Keiron O'Shea, Ryan Nash},
 title={An Introduction to Convolutional Neural Networks},
 year=2015,
 journal={arXivaij}, 
 volume={1511.08458}, 
  annote={Helpful primer into convolutional neural networks}
}

% This is an example of a URL reference
% Note you should try to identify authorship of web resources
% Also note you should include the date you last accessed the page.
@MISC{TensorFlow,
author = {Various},
title = {Tensor Flow},
month = Feb,
year = {2016},
howpublished={\url{https://www.tensorflow.org/}},
note={Accessed February 2016},
annote={Site for Google's Tensor Flow machine learning framework}
}

@MISC{CIFAR,
	author = {Various},
	title = {CIFAR},
	month = Feb,
	year = {2016},
	howpublished={\url{http://www.cs.toronto.edu/~kriz/cifar.html}},
	note={Accessed February 2016},
	annote={Site for the CIFAR-10 and CIFAR-100 datasets.}
}

@MISC{MNIST,
	author = {Various},
	title = {MNIST},
	month = Feb,
	year = {2016},
	howpublished={\url{http://yann.lecun.com/exdb/mnist/}},
	note={Accessed February 2016},
	annote={Site for the MNIST dataset.}
}

@misc{chollet2015keras,
  author = {Chollet, François},
  title = {Keras},
  year = {2015},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/fchollet/keras}},
  note={Accessed March 2016},
  annote={Keras citation as recommended by author.}
}

@book{citeulike:873540,
	Annote = {A book about the application of Pattern Recognition and Machine Learning},
    abstract = {{The field of pattern recognition has undergone substantial development over the years. This book reflects these developments while providing a grounding in the basic concepts of pattern recognition and machine learning. It is aimed at advanced undergraduates or first year PhD students, as well as researchers and practitioners.}},
    author = {Bishop, Christopher M.},
    citeulike-article-id = {873540},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387310738},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387310738},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/71008143},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387310738},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387310738},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387310738/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387310738},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387310738},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387310738},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387310738\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387310738},
    day = {01},
    edition = {1st ed. 2006. Corr. 2nd printing 2011},
    howpublished = {Hardcover},
    isbn = {0387310738},
    keywords = {dissertation},
    month = oct,
    posted-at = {2015-02-04 11:51:03},
    priority = {2},
    publisher = {Springer},
    title = {{Pattern Recognition and Machine Learning (Information Science and Statistics)}},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387310738},
    year = {2007}
}

@article{citeulike:1295398,
		Annote = {Seminal work regarding creating artificial neurons which, even though the techniques described in the book have become out of date, still forms the basis of modern ANNs},
    abstract = {{Because of the  ” all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.}},
    author = {McCulloch, Warrens and Pitts, Walter},
    booktitle = {The bulletin of mathematical biophysics},
    citeulike-article-id = {1295398},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bf02478259},
    citeulike-linkout-1 = {http://www.springerlink.com/content/61446605110620kg},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/BF02478259},
    day = {21},
    doi = {10.1007/bf02478259},
    issn = {0007-4985},
    journal = {Bulletin of Mathematical Biology},
    keywords = {dissertation},
    month = dec,
    number = {4},
    pages = {115--133},
    posted-at = {2015-02-06 13:20:58},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{A logical calculus of the ideas immanent in nervous activity}},
    url = {http://dx.doi.org/10.1007/bf02478259},
    volume = {5},
    year = {1943}
}

@article{lyz06optimization,
Annote={This document discusses the use of Weights in Deep Neural Network architectures},
    abstract = {{This paper introduces a methodology for neural network global optimization. The aim is the simultaneous optimization of multilayer perceptron (MLP) network weights and architectures, in order to generate topologies with few connections and high classification performance for any data sets. The approach combines the advantages of simulated annealing, tabu search and the backpropagation training algorithm in order to generate an automatic process for producing networks with high classification performance and low complexity. Experimental results obtained with four classification problems and one prediction problem has shown to be better than those obtained by the most commonly used optimization techniques}},
    author = {Ludermir, T. B. and Yamazaki, A. and Zanchettin, C.},
    booktitle = {Neural Networks, IEEE Transactions on},
    citeulike-article-id = {2566281},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tnn.2006.881047},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4012033},
    doi = {10.1109/tnn.2006.881047},
    journal = {Neural Networks, IEEE Transactions on},
    keywords = {annealing, architectures, methodology, network, neural, optimization, search, simulated, tabu, weights},
    number = {6},
    pages = {1452--1459},
    posted-at = {2008-10-08 01:50:33},
    priority = {0},
    title = {{An Optimization Methodology for Neural Network Weights and Architectures}},
    url = {http://dx.doi.org/10.1109/tnn.2006.881047},
    volume = {17},
    year = {2006}
}

@inproceedings{lecun2010convolutional,
Annote={The paper that first introduced Convolutional Neural Networks.},
  title={Convolutional networks and applications in vision},
  author={LeCun, Yann and Kavukcuoglu, Koray and Farabet, Cl{\'e}ment},
  booktitle={Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on},
  pages={253--256},
  year={2010},
  organization={IEEE}
}

@article{lecun1998gradient,
Annote={A discussion on the Gradient Descent optimisation algorithm.},
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@article{shotton2013real,
Annote={An paper, describing the use of synthetic data for use in machine learning.},
  title={Real-time human pose recognition in parts from single depth images},
  author={Shotton, Jamie and Sharp, Toby and Kipman, Alex and Fitzgibbon, Andrew and Finocchio, Mark and Blake, Andrew and Cook, Mat and Moore, Richard},
  journal={Communications of the ACM},
  volume={56},
  number={1},
  pages={116--124},
  year={2013},
  publisher={ACM}
}

@article{ciresan2010deep,
Annote={A useful paper about the effect of multiple layers for MNIST classification.},
  title={Deep, big, simple neural nets for handwritten digit recognition},
  author={Ciresan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={22},
  number={12},
  pages={3207--3220},
  year={2010},
  publisher={MIT Press}
}

@article{moreira1995neural,
Annote={Discussion of the use of momentum and learning rate in neural networks.},
  title={Neural networks with adaptive learning rate and momentum terms},
  author={Moreira, Miguel and Fiesler, Emile},
  journal={Technique Report 95},
  volume={4},
  year={1995},
  publisher={Citeseer}
},

@article{chapelle2002choosing,
  title={Choosing multiple parameters for support vector machines},
  author={Chapelle, Olivier and Vapnik, Vladimir and Bousquet, Olivier and Mukherjee, Sayan},
  journal={Machine learning},
  volume={46},
  number={1-3},
  pages={131--159},
  year={2002},
  publisher={Springer}
}

@article{hearst1998support,
  title={Support vector machines},
  author={Hearst, Marti A. and Dumais, Susan T and Osman, Edgar and Platt, John and Scholkopf, Bernhard},
  journal={Intelligent Systems and their Applications, IEEE},
  volume={13},
  number={4},
  pages={18--28},
  year={1998},
  publisher={IEEE}
}

