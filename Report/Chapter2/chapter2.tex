%\addcontentsline{toc}{chapter}{Development Process}\chapter{Experiment Methods}\section{Introduction}This chapter is concerned with introducing the concepts and methodologies we will be using to complete this project. The aim is to familiarise the viewer with the theory behind our experiments as well as hopefully illustrate in clear and concise terms the motivation and methods behind our experiments. This combined with the next chapter will give a complete overview of the experiment design and implementation which form the core of this project.\section{The Importance of Data in Machine Learning}For any ML problem the first and most important problem after determining the problem itself is deciding on the data.Any ML algorithm begins with data $\left(Training Data\right)$ and ends with data $\left(Test Data, Performance Data\right)$ the purpose of machine learning is to extract information based on examples so without examples it would be impossible to progress.Of course that's not all we use data for. In order to evaluate our models data is also used to drive other aspects of the ML lifecycle. We also need data to evaluate our mode's performance, and our performance data is itself a very important data decision in ML.When it comes to data more usually best, but there are cases where less better quality data is more important. Indeed, unless data is of sufficient quality we cannot use it. Quality in this sense refers to our ability to learn from it. There are many qualities in data that might make its quality poor.If for example we train a model to classify between dogs and cats but have only 1 example of a cat for every 10 dogs, then perhaps our model will perform poorly, while in other tasks that's not really an issues. Different qualities of data are needed or desirable for different tasks.Performance data is important as it  allows us to validate decisions and to direct our efforts in such a way as to achieve good general performance which is usually the objective in ML, the use of a trained model to map new examples to a learned output.A data driven approach to problems is essential in ML.\section{Dataset}A dataset is a set of data that is to be used as inputs for an ML algorithm either for Training, Testing, or both. A dataset will usually consist of a set of inputs and a set of outputs.What those sets of inputs and outputs are will depend on the type of dataset and potentially the problem  the dataset is designed to solve. For instance a dataset might be a set of images of Donald Trump and pictures of assorted barnyard animals, labeled as 'trump' and 'not-trump' This dataset might be suitable to train a model to identify pictures of Donald Trump.If we wished to use a dataset like this to identify individual animals we might struggle however. In simple terms an ML algorithm can only learn things contained in the dataset it trains on. This creates a demand for many datasets to be created for many different purposes.Creating, Normalising, and Evaluating a Dataset is a hard and complicated task, involving a lot of labour. Yet datasets are numerous as the problems they wish to solve. Choosing the correct dataset then goes hand in hand with selecting a problem.\section{Artificial Neural Networks}\subsection{Introduction}Artificial Neural Networks are a series of ML models and methods that are based on a naive model of the biological function of neurons. They have origins as early as the 1940s \cite when Mathematical Biophysicists were studying the functions of neurons and were attempting to model them mathematically.Neural Networks have progressed tremendously since those days but many of the fundamental concepts remain the same. At their core they still have basic simulated neurons and they still are trying to completely emulate the functions of a real neuron whether than be human, cat, or another organism. \subsection{Optimisers}\subsection{Loss Functions}\subsection{Activation Functions}\subsubsection{ReLU}\subsubsection{Softmax}\subsection{Perceptrons}\subsection{Convolutional Neural Networks}\subsubsection{Structuring a CNN}\section{Network training}\section{Network evaluation}\subsection{Confusion Matrices}\subsection{Performance Metrics and their Meaning}\subsection{The Components of a Classification Report}\subsection{Confusion Matrices}\subsection{Training History}\subsection{Receiver Operating Characteristic}\section{Overfitting}\subsection{Dropout}\subsection{Data Augmentation}\subsection{Cross Validation}